\begin{problema}[Procesos de ramificaci\'on a tiempo continuo]
    Sea $\mu$ una distribuci\'on en $\na$. A $\mu_k$ lo interpretamos como la probabilidad de 
    que un individuo tenga $k$ hijos. Nos imaginamos la din\'amica de la poblaci\'on como sigue: 
    a tasa $\lambda$, los individuos de una poblaci\'on se reproducen. Entonces tienen $k$ hijos 
    con probabilidad $\mu_k$. Se pueden introducir dos modelos: uno en que el individuo que se 
    reproduce es retirado de la poblaci\'on (nos imaginamos que muere) y otro en que no es retirado 
    de la poblaci\'on (por ejemplo cuando se interpreta a la poblaci\'on como especies y a sus 
    descendientes como mutaciones). En el caso particular del segundo modelo en que $\mu_1=1$, 
    se conoce como proceso de Yule. 

    \begin{enumerate}
        \item[(i)]      [\ref{problema5_6:inciso1}]
            Especifique un modelo de cadenas de Markov a tiempo continuo para cada uno de los
            modelos anteriores. A estos procesos se les conoce como procesos de ramificaci\'on
            a tiempo continuo.\pn
    \end{enumerate}

        Nuestro primer objetivo ser\'a encontrar una relaci\'on entre procesos de ramificaci\'on a
        tiempo continuo y procesos de Poisson compuestos. Sea $N$ un proceso de Poisson  y $S$ una
        caminata aleatoria independiente de $N$ tal que $\proba{S_1=j}=\mu_{j-1}$ \'o $\mu_{j}$
        dependiendo de si estamos en el primer caso o en el segundo. Sea $k\geq 0$ y definamos a
        $X_t=k+S_{N_t}$.
        
    \begin{enumerate}[resume]
        \item[(ii)]     [\ref{problema5_6:inciso2}] 
            Diga brevemente por qu\'e $X$ es una cadena de Markov a tiempo continuo e identifique 
            su matriz infinitesimal para ambos modelos.\pn
    \end{enumerate}

        Sea ahora $\tau=\min\set{t\geq 0: X_t=0}$ y $Y_t=X_{t\wedge \tau}$. 
        
    \begin{enumerate}[resume]
        \item[(iii)]    [\ref{problema5_6:inciso3}] 
            Argumente por qu\'e $Y$ es una cadena de Markov a tiempo continuo e identifique su 
            matriz infinitesimal.\pn
            
        \item[(iv)]     [\ref{problema5_6:inciso4}] 
            Argumente por qu\'e existe un \'unico proceso $Z$ que satisface
            \begin{esn}
                Z_t=Y_{\int_0^t Z_s\, ds}
            \end{esn}
            y que dicho proceso es un proceso de ramificaci\'on a tiempo continuo. Sugerencia: Recuerde que las 
            trayectorias de $Y$ son constantes por pedazos.\pn
    \end{enumerate}

    Ahora nos enfocaremos en el proceso de Yule. 

    \begin{enumerate}[resume]
        \item[(v)]      [\ref{problema5_6:inciso5}]
            Escriba las ecuaciones backward de Kolmogorov para las probabilidades de transici\'on 
            $\imf{P_t}{x,y}$. Al argumentar por qu\'e $\imf{P_{t}}{x,x}=e^{-\lambda x}$, resuelva 
            las ecuaciones backward por medio de la t\'ecnica de factor integrante (comenzando con 
            $\imf{P_t}{x,x+1}$) y pruebe que
            \begin{esn}
                \imf{P_t}{x,y}=\binom{y-1}{y-x} e^{-\lambda x t}\paren{1-e^{-\lambda t}}^{y-x}.
            \end{esn}\pn
        
        \item[(vi)]     [\ref{problema5_6:inciso6}]
            Al utilizar la f\'ormula para la esperanza de una variable binomial negativa, 
            pruebe que
            \begin{esn}
                \imf{\se_x}{Z_t}= xe^{\lambda t}.
            \end{esn}\pn
        
        \item[(vii)]    [\ref{problema5_6:inciso7}]
            Pruebe que $e^{-\lambda t}Z_t$ es una martingala no-negativa y que por lo tanto 
            converge casi seguramente a una variable aleatoria $W$.\pn
        
        \item[(viii)]   [\ref{problema5_6:inciso8}]
            Al calcular la transformada de Laplace de $e^{-\lambda t}Z_t$, pruebe que $W$ tiene 
            distribuci\'on exponencial. Por lo tanto, argumente que casi seguramente $Z$ crece exponencialmente.
            %La distribuci—n l’mite est‡ tomada de Beroin-Goldschmidt, ellos citan y corrigen un error de Athreya.
            \pn
    \end{enumerate}
\end{problema}

\begin{proof}
    \subsection{Inciso (i)} \label{problema5_6:inciso1}
    \input{tarea5/problema5_6/inciso5_6_1.tex}
    \newpage

    \subsection{Inciso (ii)} \label{problema5_6:inciso2}
    \input{tarea5/problema5_6/inciso5_6_2.tex}
    \newpage

    \subsection{Inciso (iii)} \label{problema5_6:inciso3}
    \input{tarea5/problema5_6/inciso5_6_3.tex}
	\newpage
	
    \subsection{Inciso (iv)} \label{problema5_6:inciso4}
    \input{tarea5/problema5_6/inciso5_6_4.tex}
    \newpage
    
    \subsection{Inciso (v)} \label{problema5_6:inciso5}
    \input{tarea5/problema5_6/inciso5_6_5.tex}
    \newpage

    \subsection{Inciso (vi)} \label{problema5_6:inciso6}
    \input{tarea5/problema5_6/inciso5_6_6.tex}
    \newpage

    \subsection{Inciso (vii)} \label{problema5_6:inciso7}
    \input{tarea5/problema5_6/inciso5_6_7.tex}
	\newpage
	
    \subsection{Inciso (viii)} \label{problema5_6:inciso8}
    \input{tarea5/problema5_6/inciso5_6_8.tex}
\end{proof}