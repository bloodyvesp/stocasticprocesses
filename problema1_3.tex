\begin{problema}
	\emph{Tomado de Mathematical Tripos, Part III, Paper 33, 2012, \url{http://www.maths.cam.ac.uk/postgrad/mathiii/pastpapers/}}

	Sean $\paren{X_i,i\in\na}$ variables aleatorias 
	independientes con $\proba{X_i=\pm 1}=1/2$. Sean $S_0=0$ y $S_n=\sum_{i=1}^n X_i$. 

	\begin{enumerate}
		\item[(i)] Sea $T_1=\min\set{n\geq 0:S_n=1}$. Explique por qu\'e $T_1$ es un 
		tiempo de paro y calcule su esperanza.
		
		\item[(ii)] Mediante el inciso anterior, construya una martingala que converge 
		casi seguramente pero no lo hace en $L_1$.
		
		\item[(iii)] Sea $M_n$ la martingala obtenida al detener a $-S$ en $T_1$. Utilice la solución al
		Problema de la Ruina para probar que $\mw(max_n M_n \geq M) = 1/(M+1)$ para todo $M \geq 1$. Concluya que
		$\E(max_m M_n) = \infty$ y que por lo tanto $\E(max_{m\leq n} M_m) \rightarrow \infty$ conforme 
		$n \rightarrow \infty$. Finalmente, deduzca que no puede haber una desigualdad de tipo Doob cuando $p=1$.
		
		\item[(iv)] Sea $T=\min\set{n\geq 2:S_n=S_{n-2} + 2}$ y $U=T-2$. ?`Son $T$ y $U$ 
		tiempos de paro? Justifique su respuesta.
		
		\item[(v)] Para la variable $T$ que hemos definido, calcule $\esp{T}$. 
	\end{enumerate}

	\defin{Categor\'ias: } Tiempos de paro, problema de la ruina
\end{problema}

\begin{proof}
	\begin{enumerate}
		\item[(i)]
		Sea $T_1=\min\set{n\geq 0:S_n=1}$. Explique por qu\'e $T_1$ es un 
		tiempo de paro y calcule su esperanza.\\
		
			Consideremos a la filtración $(\F_n)_{n\in\N}$ como la filtracion 
			generada por $X_1, X_2, \dots$.\\

			Es decir, $F_0 = \{\emptyset, \Omega\}$, $\F_n = \sigma(X_1, X_2, \dots, X_n)$\\
		
			Nótese que $S_0$ es medible bajo cualquier sigma álgebra por ser constante, en particular bajo
			$\F_0$.\\
		
			Basta demostrar que $(T_1 = n) \in \F_n$ para ver que $T_1$ es tiempo de paro. $T_1$ 
			representa el primer tiempo en que la suma es igual a $1$. Es decir, para cualquier 
			momento anterior, la suma no es $1$.
		
			Eso escrito en símbolos significa:
		
			$$(T_1 = n) = \bigcap_{i=0}^{n-1}(S_i \not= 1) \cup (S_n = 1).$$ 
		
			Para $n=0$, $(S_0 = 1) = \omega \in \F_0$. \\
		
			Como $(S_i \not= 1) \in \F_j$ siempre que $i \leq j$. Para $n>0$, $(T_1 = n)$ es el resultado de 
			unir e intersectar conjuntos $\F_n$-medibles, lo cual resulta $\F_n$-medible.\\
		
			Para $m \in \N$. Definamos $T_m = min\{n \geq 0 : S_n = m\}$ 
			(Nótese que para el caso $m=1$, esta definición	coincide con la definición previa de $T_1$).\\
			
			Para $a,b \in \N$, podemos definir el tiempo de paro $T_{a,b} = T_{-a} \wedge T_b$, y 
			corresponde al 	tiempo de paro del problema de la ruina. Para este tiempo de paro ya conocemos 
			la esperanza y es
			$$\E(T_{a,b}) = ab.$$\\
			
			Ahora, definamos la sucesion de variables aleatorias $T_{1,1}, T_{2,1}, T_{3,1}, \dots, T_{n,1}, 
			\dots$. Notemos que si $a>a' \in N$ entonces $T_{-a} > T_{-a'}$, pues $T_{-a}$ es la primera vez
			que se llega a $-a$, y para poder alcanzar $-a$ era necesario haber pasado por $-a'$.
			De aqui tenemos que si $a>a'$, entonces $T_{a,1} \geq T_{a',1}$. De donde nuestra suceción es 
			no decreciente.\\
			
			Por otro lado, que si $a>a' \in N$ entonces $T_{-a} > T_{-a'}$ implica que $T_{-n} n \in \N$ es 
			una suceción extrictamente creciente y por lo tanto 
			$\lim\limits_{n \rightarrow \infty} T_{-n} = \infty$, con esto tenemos que el límite de nuestra 
			suceción es 
			$$		
			\lim_{n\rightarrow\infty} T_{n,1} = 
			\lim_{n\rightarrow\infty} T_{-n} \wedge T_1 = 
			\infty \wedge T_1 = 
			T_1
			$$

			Tenemos todos los ingredientes para usar Teorema de convergencia monótona sobre nuestra suceción
			y la variable $T_1$. Nuestra sucecion es monótona y converge puntualmente a $T_1$. Utilizando
			dicho teorema obtenemos:
			
			$$
			\E(T_1) = 
			\E(\lim_{n\rightarrow\infty} T_{n,1}) = 
			\lim_{n\rightarrow\infty} \E(T_{n,1}) = 
			\lim_{n\rightarrow\infty} n\cdot 1 =
			\infty.
			$$
			
			Lo cual era intuitivo. Si $\E(T_1)$ fuese finito, diría que existe un número de volados donde
			uno puede apostar con mucha certeza que ganará un peso después de jugar "cerca" de esa cantidad
			de volados. Intuitivamente, esto vuelve injusto un juego de volados donde la moneda es
			justa.\\
			
		\item[(ii)]
		Mediante el inciso anterior, construya una martingala que converge 
		casi seguramente pero no lo hace en $L_1$.\\

			
			En el ejercicio 4 se probará que si $T$ y $S$ son tiempos de paro, entonces $T\wedge S$ también 
			es tiempo de paro. Con esto tenemos que si $T_1$ es tiempo de paro, entonces $T_1 \wedge n$ con 
			$n \in \N$ también es tiempo de paro. Definimos entonces 
			$$M_n = S_{T_1 \wedge n}.$$
			
			Veamos que los $M_n$ forman una martingala.
			
			\begin{itemize}
			 	\item[(a)] 
				 	$M_n$ es adaptada a la filtración.
			 		$$
			 		M_n(w) = S_{T_1 \wedge n}(w) = 
			 		S_{T_1 \wedge n (w)}(w) = 
			 		\sum_{k=1}^{T_1 \wedge n (w)} X_k = 
			 		\sum_{k=1}^{n} (X_k \cdot \indic_{T_1 \geq k})(w).
			 		$$
			 		
			 		De donde, podemos escribir:
					\begin{equation}\label{problema1_3:descomposicion_de_M_n}
			 			M_n = \sum_{k=1}^{n} (X_k \cdot \indic_{T_1 \geq k}).
					\end{equation}								 		
			 		
			 		Recordemos que $X_k$ es $\F_n$-medible para toda $k \leq n $. Por ser
			 		$T_1$ tiempo de paro, los conjuntos $A_k = \{T_1 = k\}$ y 
			 		$B_k = \{T_1 \leq k\}$	son $F_k$ medibles y por lo tanto 
			 		$A_k \cup B_k^c = \{ T_1 \geq k\}$ también lo es. De aquí que 
			 		$\indic_{T_1 \geq k}$ es $\F_k$-medible y por lo tanto también $\F_n$-medible
			 		para toda $n$ tal que $n \geq k$.\\
			 		  
			 		Entonces $M_n$ es suma y productos de funciones $\F_n$-medibles y por lo tanto
			 		$F_n$-medible. Que es lo que queríamos demostrar.\\
			 		
			 	\item[(b)]
			 		$M_n \in \mathbb{L}_1$\\
			 		
			 		De (\ref{problema1_3:descomposicion_de_M_n}) podemos ver que $M_n$ es 
			 		suma finita de variables acotadas. Por lo tanto $M_n \in \mathbb{L}_1$.\\
			 		
			 	\item[(c)] Ahora probaremos que	$\E(M_{n+1} | \F_{n}) = M_{n}$\\
			 		
			 		Primero:
			 		\begin{align}
			 			\E(M_{n+1} | \F_{n}) &= \E( S_{T_1 \wedge (n+1)} | \F_{n}) = 
			 			\E\bigg( \sum_{k=1}^{n+1} (X_k \cdot \indic_{T_1 \geq k})\bigg| \F_{n}\bigg) \\	 			
			 			& =\E\bigg( \sum_{k=1}^{n} (X_k \cdot \indic_{T_1 \geq k}) \bigg| \F_{n}\bigg) +
			 			\E\bigg((X_{n+1} \cdot \indic_{T_1 \geq n+1}) \bigg| \F_{n}\bigg) \\
			 			&\mbox{(Este paso es gracias a que $X_k$ y $\indic_{T_1 \geq k}$ son $\F_n$-medibles)}\\
			 			& = \sum_{k=1}^{n} (X_k \cdot \indic_{T_1 \geq k}) + 
			 			\E((X_{n+1} \cdot \indic_{T_1 \geq n+1}) | \F_{n}) \\
			 			& = S_{T_1 \wedge n} + \E((X_{n+1} \cdot \indic_{T_1 \geq n+1}) | \F_{n}) \\
			 			& = M_n + \E((X_{n+1} \cdot \indic_{T_1 \geq n+1}) | \F_{n})
			 		\end{align}
			 		
			 		Entonces, nos basta probar que $\E(X_{n+1} \cdot \indic_{T_1 \geq n+1} |
			 		 \F_{n}) = 0$ para terminar nuestra demostración.\\
			 		 
					Sean $A = \{T_1 = n\}$ y $B = \{ T_1 \leq n\}$. Por ser $T_1$ tiempo de paro,
					$A$ y $B$ son $\F_n$-medibles. Por lo tanto $B \setminus A$ también es $\F_n$-medible. 
					Notemos que $\{T_1 \geq n+1\} = (B \setminus A)^c$. Por lo tanto $\{T_1 \geq n+1\}$ es
					$\F_n$-medible. De donde  $\indic_{T_1 \geq n+1})$ es $\F_n$-medible.\\
					
					Con esto, ahora tenemos que:
					\begin{align}
						\E((X_{n+1} \cdot \indic_{T_1 \geq n+1}) | \F_{n}) &= \indic_{T_1 \geq n+1} \cdot \E(X_{n+1} | \F_{n}) \\
						&\mbox{(Este paso es gracias a que los $X_n$ son independientes)} \\
						&=\indic_{T_1 \geq n+1} \cdot \E(X_{n+1} ) \\
						&=\indic_{T_1 \geq n+1} \cdot 0 \\
						&= 0
					\end{align}	
					
					Como queríamos demostrar.
			\end{itemize}
			
			Ahora que tenemos que $(M_n)_{n \in \N}$ es martingala, confirmemos que converge casi seguramente.\\
			
			Notemos que $(T_1 \wedge n)_{n \rightarrow \infty} \rightarrow T_1$ c.s.\\
			
			De aquí que $(M_n)_{n \rightarrow \infty} = (S_{T_1 \wedge n})_{n \rightarrow \infty} = S_{T_1}$ c.s. \\				
			
			Veamos que la convergencia no ocurre en $\mathbb{L}_1$. \\
						
			Dado que $T_1 \wedge n$ es un tiempo de paro acotado para toda $n \in \N$,
			podemos aplicar el Teorema de Muestreo Opcional de 	Doob. 
			El cual nos dice que $\E(M_n) = \E(S_{T_1 \wedge n}) = \E(S_0) = 0$.\\
			
			Por otro lado, por definición de $T_1$, $S_{T_1} = 1$ c.s.	De donde $\E(S_T) = 1$.\\
			
			\begin{align}
				\E(M_n) = 0 \not\rightarrow 1 = \E(S_{T_1}).
			\end{align}			
			
			Y con esto, queda demostrado que la convergencia no se da en $\mathbb{L}_1$.\\
			
		\item[(iii)] 
		
		Sea $M_n$ la martingala obtenida al detener a $-S$ en $T_1$. Utilice la solución al
		Problema de la Ruina para probar que $\mw(max_n M_n \geq M) = 1/(M+1)$ para todo $M \geq 1$. Concluya que
		$\E(max_m M_n) = \infty$ y que por lo tanto $\E(max_{m\leq n} M_m) \rightarrow \infty$ conforme 
		$n \rightarrow \infty$. Finalmente, deduzca que no puede haber una desigualdad de tipo Doob cuando $p=1$.\\
		
			Definimos $M_n = -S_{T_1 \wedge n}$. Notemos que $M_n$ únicamente toma valores en $[-1, \infty]$.
			Para calcular $\mw(max_n M_n \geq M)$ notemos primero que:
			\begin{align}
				\mw(max_n M_n \geq M) = 1 - \mw(max_n M_n < M).
			\end{align}\\
			
			$max_n M_n < M$ significa que $M_n$ nunca alcanza el valor $M$.\\
			 
			Intentando hacer analogía con el problema de la ruina, pensemos en dos concursantes,
			uno con $1$ peso y otro con $M$ pesos. Nunca alcanzar $M$ significa que nunca gana el que tiene $1$ peso.\\
			
			Esta probabilidad ya la conocemos y es 
			
			\begin{align*}
				\mw(max_n M_n < M) = \frac{M}{M + 1}
			\end{align*}
				
			Por lo tanto
			
			\begin{align}
				\mw(max_n M_n \geq M) 	&= 1 - \mw(max_n M_n < M) \\
										&= 1 - \frac{M}{M + 1}\\
										&= \frac{M+1}{M+1} - \frac{M}{M + 1}\\
										&= \frac{1}{M+1}
			\end{align}
			
			Utilizando este resultado:
			\begin{align} \label{problema1_3:esperanza_del_maximo_de_M_n}
				\E(max_n M_n) 	&= - \mw(max_n M_n = -1) + \sum_{M=1}^{\infty} \mw(max_n M_n \geq M) \\
								&= - \mw(max_n M_n = -1) + \sum_{M=1}^{\infty} \frac{1}{M+1} \\ 
								&= - \mw(max_n M_n = -1) + \infty \\
								&= \infty
			\end{align}						
			
			Ahora, tenemos que:
			\begin{align}
				\|\overline{M_{n}^{+}}\|_1  &=    \E{\overline{M_{n}^{+}}} \\
											&=    \E{\max_{m \leq n}M_m^+} \\
											&\geq \E{\max_{m \leq n}M_m}										
			\end{align}
				
			Donde, el último término, tiende a infinito en base al resultado 
			(\ref{problema1_3:esperanza_del_maximo_de_M_n}).

			Por otro lado:
			\begin{align}
				\|M_n^+\|_1=\|-S_{T_{1\wedge n}}^{+}\|_1  \longrightarrow  \|-S_{T_1}^+\|_1 = 0 < \infty
			\end{align}
			
			Por lo tanto, no existe número $K$, tal que
			\begin{align}
				 \|\overline{M_n^+}\|_1 \leq  K \|M_n^+\|_1
			\end{align}
			
			En otras palabras, no tenemos una desigualdad de tipo Doob para $p=1$.\\
			
		\item[(iv)]  
		Sea $T=\min\set{n\geq 2:S_n=S_{n-2} + 2}$ y $U=T-2$. ?`Son $T$ y $U$ 
		tiempos de paro? Justifique su respuesta.\\
					
			Intuitivamente, $T$ significa, el primer tiempo tal que ganamos en dos volados consecutivos.
			También intuitivamente, esto debería ser un tiempo de paro.
			
			Veamos que efectivamente así ocurre. Utilizando la siguiente prueba por inducción:\\
			
			\textbf{Base de inducción:}		
				\begin{align}
					\{T = 0\} 		&= \emptyset  				& 	\in \F_0 \\
					\{T = 1\} 		&= \emptyset  				& 	\in \F_1 \\
			   		\{T = 2\} 		&= \{ X_1 = 1, X_2 = 1\} 	&	\in \F_2
				\end{align}	\\					
			
			\textbf{Hipótesis de inducción:}\\
			
				Supongamos que $\{T = n\} \in \F_n$ para cierto $n \geq 2$.\\
				
			\textbf{Paso inductivo:}
				
				\begin{align}
					\{T = n + 1 \} = \{ X_n = 1, X_{n+1} = 1\} \setminus \bigcup_{i=0}^{n} \{T = i\}.
				\end{align}				
			
				Es claro que $\{ X_n = 1, X_{n+1} = 1\} \in \F_{n + 1}$ y que por hipótesis de inducción
				$\bigcup_{i=0}^{n} {T = i} \in \F_n \subset \F_{n + 1}$. Por lo tanto
				$\{T = n + 1 \} \in \F_{n+1}$ para toda $n \geq 2$ y con esto termina la demostración.\\
				
			Ahora, intuitivamente $U$ significa el momento justo antes de ganar dos volados consecutivos.
			Esto, quedría decir que tenemos información sobre eventos que aún no ocurren. Así que intuitivamente
			esto no debería ser un tiempo de paro.\\
			
			Efectivamente, si tomamos como ejemplo el conjunto: 
				\begin{align}
					\{ U = 1 \} = \{ T - 2 = 1\} = \{ T = 3\} = \{X_1 = -1, X_2 = 1, X_3 = 1\}
				\end{align}		\\
					
			Es fácil notar que es un conjunto que pertenece a $\F_3$, pero no a $\F_1$. Pues $\F_1$
			no contiene información alguna sobre $X_2$ y $X_3$. Así que el conjunto más pequeño de $\F_1$ 
			que contiene a $\{ U = 1 \}$ es $\{ X_1 = -1 \}$.\\
			
		\item[(v)] 
		Para la variable $T$ que hemos definido, calcule $\esp{T}$.\\
		
		   	Primero, platicaré de manera intuitiva cómo vamos a proceder para solucionar este problema.\\
		
		   	Imaginemos un juego de casino a base de un juego de volados con las siguientes reglas:\\
		   	\begin{itemize}
		   			\item En cada turno, cada jugador tiene que apostar todo el dinero que tiene.
		   			\item Si un jugador se queda sin dinero, tiene que abandonar el juego.
		   			\item Si cae ``sol" cada jugador recibe el doble de lo que había apostado en ese turno.  
		   	\end{itemize}
		   
		   	\;El casino tiene dinero infinito y cada habitante cuenta con exactamente $1$ peso antes de
		   	iniciar el juego.\\
		   
		   	Además, en cada nuevo turno entra exactamente un nuevo jugador al juego.\\
		   
		   	Para nuestro problema, supongamos que $X_n = 1$ significa que en el $n$-ésimo turno, salió sol.
		   	Entonces, $T$ nos indica cuando es la primera vez que caen dos soles consecutivos.\\
		   
		   	Sea $D_n$ la variable que indica cuánto dinero ha ganado el casino para el tiempo $n$.\\
		   
		   	Observemos que en el momento que cae ``águila", todo jugador pierde todo su dinero y abandona el juego.
		   	Y que por cada jugador que pierde, el casino gana exáctamente $1$ peso (pues cada jugador en cada
		   	turno apuesta todo el dinero que posee, es decir el peso con el que empezó y todo lo que le habia
		   	ganado al casino).\\
		   
		   	Entonces, al tiempo $T-2$, todo mundo había perdido. Es decir que al tiempo $T-2$ el casino ha ganado
		   	$T-2$ pesos.\\
		   
		   	Luego, al tiempo $T-1$, ha caido un sol y hay exactamente un jugador al que el casino tuvo 
		   	que pagar $1$ peso.\\
		   
		   	Al tiempo $T$, al jugador del turno pasado el casino tuvo que darle $2$ pesos y al jugador del nuevo
		   	turno tuvo que darle $1$ peso.\\
		   
		   	Entonces, ya podemos decir cuanto dinero ha ganado el casino al tiempo $T$.
			\begin{align}\label{problema1_3:Dinero_al_tiempo_T}
				D_T = T-2 - 1 - 3 = T - 6. 
			\end{align}					   
		   
		   	Notemos que además el juego es justo, en cada turno cada jugador tiene $1/2$ de probabilidad de
		   	ganar el $2^t$ y $1/2$ de probabilidad de perder $2^t$. Es decir, la esperanza es $0$.\\
		   	
		   	$D_n$ es suma de este tipo de variables y por lo tanto su esperanza también será $0$.\\
		   
		   	Esto, nos da la intuición de que $D_n$ es martingala, Pero eso es la parte que demostraremos más adelante.\\
		   
			Suponiendo que ya demostramos que es martingala, entonces por teorema del muestrueo opcional de Doob
			tenemos $\E(D_T) = \E(D_1) = 0$. De (\ref{problema1_3:Dinero_al_tiempo_T}) concluimos
			\begin{align}
				0 = \E(T - 6) = \E(T) - 6
			\end{align}
			
			De donde $\E(T) = 6$.\\
			
			Ahora, para terminar con las formalidades, definamos bien a $D$ y comprobemos que es martingala. 
			
			
		   
	\end{enumerate}
\end{proof}